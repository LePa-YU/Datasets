SPEAKER 0
so welcome everyone. We are here at the start of module for the module that is interrupted by reading week or maybe interrupted. It's not the right word happily merged with Reading week, which gives us a chance to kind of take a breath because it's been kind of breakneck. There's been a lot of things do every week. And this module, we're going to slow things a little bit in the sense that we spaced over a longer period of time. I'm just keeping an eye on the chat and I don't know those facial reactions. Yeah, I don't know how to decode them, but I'm going to hope that it's something positive and affirmation for taking a pause or slowing things down. And a typically for the chorus going with the flow. Good, That's all we can do. Just go with the flow. We've been using our class times to like come together briefly and then to do these breakouts and do all these activities. And today we're going to have a kind of a more say, Traditional mode where I'm probably just gonna use the whole time to go through this resource pack on prototyping. And although I say this like it's just not fun to talk for 80 minutes or 70 minutes, whatever the case may be right now, hang on, let me set an alarm. So I don't go too long. I would like you too raise your hand, ask questions, put it in the chat, we have people standing by monitoring to flag it and, you know, feedback comments to give it a little bit more of a liveliness because otherwise it can be a little bit boring. So I'm going to set my timer just so I don't lose track of time, which often happens.

SPEAKER 1
Okay, so this module is all about prototyping and you're

SPEAKER 0
going to in your module activities do prototyping and what are you gonna prototype is the kind of interesting question. So obviously the prototyping has to be embedded in some kind of overarching process. So we're going to take this class to really talk about the project, the overarching process and embed the prototyping within their. And I hope by the end of this, If you have been wondering like what are all these different pieces were doing and like module two and three and like how does this connect with user interfaces? I hope that this um chunk of material answers that question either explicitly or if you maybe have the question lingering, it implicitly answers it uh Rigi is flagging me saying, are we not going through the quiz? And I, to be totally honest, Just launching in the material. So why don't I finish this? And then I've set my timer to finish at 11:05 and then we'll do the quiz at that point. Thank you for that. Uh Oh and there's a whole list of questions. Okay. Okay. Good. Yes, that's awesome, thank you for that. See how good teamwork is uh so to those who are listening to this, we're talking about reviewing the quiz from module to so those have been taken and the grading is done and people have questions about the I guess the grading and the what the correct answers are. So but the module three quizzes postponed till next week. Uh huh. Alice is asking are we supposed to see our responses to the White house and round? Yes they're all released. Are you saying that someone has a response that they're not seeing Eye released everything? A lot of people were asking that one Alice, are you saying Alice right now? You can't see your responses. You can't see yours. A lot of people have the same issue. Okay. I released everything. So if you're not seeing them that suggests something that's happening you can't see your okay. You won't be able to see you can only see the ones in your learning semi pod, you're half pod. Could it be that you can't see your own? It's blank. Yeah it's a blank page. Okay. Okay we have to flag this. I can't troubleshoot it. Minor. Maybe you could go poke around and see what's going on with doing the right now. Perfect. Perfect. Maybe we can solve that life. Okay we'll get that solved. I don't know what's going on. It's it's like you roll the dice with modal or E class as we call it but it's actually middle is that going to work is it not? We have deployed this massive piece of software infrastructure that all the courses depend on. And somehow it's just kind of mhm If rashes it goes down, it behaves strangely. It's exactly what you want for like, you know, large scale organizational deployment to 50,000 students in a mission critical way. It's just a snarky. But Oh mother, uh This three was postponed. Yeah, jintao. I think there's some confusion there. Okay, let me start because we've got a 61 slides, so that's like less than a minute of slide, which not over slide, it has to talk about but you know me, I can easily go and elaborate and fill things out so I have to try and stay on track here. Okay, so here it looked about spacing here. So the overall trajectory is like here's the recap of like material that has been established prior to this moment. And then we're talking about like design practice writ large. Then we're going to talk about double diamond. I mentioned that before and then prototyping within the double diamond. So the art goes like this. Mm So what recap is needed. So all that seemingly super abstract stuff back in knowledge One Knowledge knowledge practices is now like this is the moment because we had to establish what a methodology is and what a method is and distinguish the two. So as a recap methodology is a system of methods that get used in a particular activity. Let's just say it has an underlying rationale and there's a particular strategy, a particular epistemological stance, underlying the whole thing and methods are little um pieces, let's say that fit within an overarching methodology. Their particular procedures for accomplishing or approaching something. So it's like a tool. And the thing that is so possibly confusing and just messes everything up is the major methodology that is the engine for producing much of our knowledge is called a method. So the science scientific approach is a methodology. It's a it's a framework, it's an epidemic stance but it gets called the scientific method but it's not a method at all. Within the scientific method, it's actually methodology. We have all these particular tools that get used and I took pains in the resource uh for knowledge and knowledge practices to say like we have this whole umbrella of of approaches for generating new knowledge. A lot of them are evidence based. Some of them are not used critical uh analysis and argumentation but of all the empirical approaches, some of them are science based on some of them are not so to have like a really broad umbrella for how it is. We know the things we know because in design in particular, despite what some people might think a lot of it does not makes use of knowledge that does not come from the scientific method, these are practice based approaches. So we have method methodology and we have these four core activities research generating ideas, prototyping and evaluation. I'm just watching the chat Alice. You just have nothing showing up for you know quiz. No wait hat round. I don't know. I'm taking down everyone's names who don't have the quiz showing up and I'll flag it to be checked after class. That's so strange. Okay we'll have to look into that. Well thank you for raising it because otherwise we just wouldn't know. Okay so we have these four core activities. We have methodologies for each. This is like peeling back all the layers because otherwise if you say like here's how design works and you just like give a recipe. I think that just obscures a lot of the important nuance in detail. So we've covered now research ideation, we're going to do prototyping and we'll do evaluation. So the structure of the courses to spend a module on each of these four core activities. So in terms of research we talked about approaches based on empirical evidence and science and non science based approaches. We used talked about argumentation, critical analysis. You actually had as a module activity doing qualitative data analysis. That's what the dark pattern exercise was. So this is called thematic analysis and of qualitative data via coding. Not computer coding, not like programming code but qualitative data coding. And that's like a bread and butter technique that gets used a lot when you have qualitative data. It was very well defined in the sense that the themes were already emerged. So you didn't use like a grounded theory approach to discover what the themes were? We were told in advance. The themes are here the seven dark patterns. But nonetheless you get a sense of what it's like to work with this kind of data and to derive findings from it. So we have many methodologies for conducting research and then for uh ideation. This became very abstract. I know, but I really wanted you to experience firsthand first, a very particular technique which is the scamper technique. That's a particular method within the broad range of methodologies for ideation. And we also were exposed to the six thinking hats, which is actually a methodology. It's a system, it's a systemic approach that has a certain worldview, a certain stance and within that methodology there are particular tools that you can use and we did one of them which was a particular sequence of blue, white, green blue hat. Thinking so now you've at this point in the course been exposed to two activities. A methodology for each and specific methods for each. So you can see the overall logic in the course design. So, this module is about prototyping. Now we're dot dot dot So like what are the methodologies and what are I have my frog and what are some particular methods within their So the method part is easy, I'll tell you right now you're going to do a prototyping exercise in Fig MMA. But where does that fit in with like what is the overall methodology and how does prototyping fit in with design? That's it's really important to me why? Because Fig MMA can come and go like all kinds of tools will come and go. These things tend to have short life cycles in the sense of having like four or five years and then the next tool comes and then there's paradigm shifts, but what lasts for you is the knowledge of process so that you can say, okay, we're not using figure anymore. Fig mazelike old questioned in five years. So we're just going to take the same thing and apply it to whatever new tool, it's the same version that you hear when you're being taught core programming concepts for some reason, let's say you're going to use like Eiffel or some language that you think is not relevant to the world. And then the professors will tell you, it doesn't matter so much the programming language, it's the underlying concepts and if you know the concepts, you can just apply them in whatever language you're in, what's important, for instance, is strong typing. So whatever strongly typed language you're using fine or weak typing, so it happens to be python fine, but it can be some other weekly type language later. Okay, okay, man, is finding out. Yeah, what's going on. Okay, okay, so this is this is an approach to teaching? That is very uh big picture? Like here's, you know the thing and then we're diving in and I just want to acknowledge that not every learns that way and some people find this actually frustrating. They want like the concrete thing first and then the big picture actor, but there's only one in me and we have like one kick at the can. So I prefer like here's the big picture and then let's drill down. But if this is not working for you just be patient and you can approach it a different way. Okay. This question used to be in previous course what is the best practice for design? But it was a trick question and it was too subtle and it worked a little bit too well because people somehow thought that there is a best practice. I'm getting all these alerts. Do you see them on your my screen? I hope not. Okay, good. Because it's all I was in a talk yesterday a research talk and the presenter was sharing their screen and in the middle of the presentation all these email alerts kept coming up, your prescription for blah blah blah is ready and your contact lens and I was like, oh that's mortifying like all this person's personal health information is on display to like this huge audience. So uh that's just yeah, okay, I'm glad that my email alerts are not showing up. I don't want so is there a best practice for design? I changed it from what is the best practice to? Is there? So I could answer it really um simply which is is there a best practice? No no no. And I want to nuance that. So before getting into it first let's talk about what is the best practice and what is meant by benchmarking. These are terms from industry as opposed to academia and you may or may not get exposed to the terms but if you have an internship or if you work in any kind of corporate setting or maybe not even like it's just kind of the buzz word lingo of contemporary organizational discourse. So a best practices nothing like scientific is just a procedure that is accepted or prescribed as being the correct one or most effective. And I put correct and most effective quotes because really this definition doesn't tell us anything unless you actually say what is correct or most effective mean in the context. But to illustrate this with some examples like in the practice like nursing practitioner in practitioners there is a best practice for intra muscular injections for example or there's a best practice and project management for doing work breakdown structuring. So it's just a way to like talk about the realm of like human functioning so that we can name it and measure it and this okay we can have a whole digression of like the new liberal moment and why this is important for measuring productivity and economic growth. Let's put that aside. So we just talk about best practices away to identify this thing that we found to be like the best thing, the best way to do things. Best practices are not established through scientific method there often based on empirical evidence but not proven through kind of an experimental design that kind of knowledge generation. It's not common although it does exist in some safety critical approaches, there will be scientifically proven best practices. So for instance if you're designing a space shuttle and there is going to be a best practice for designing oxygen delivery systems to the passengers or something like that, not passengers astronauts, the mission specialists, benchmarking is a practice of comparing business processes and performance metrics to industry best or you know to practices among companies. So these kinds of studies can be undertaken undertaken internally or externally. So your for instance undertook an internal benchmarking study for service delivery to um two like the university internal community. So if you're an employee and you're like window is broken and you submit a service request, like someone fix my window. There's like a whole department of you know people that are responsible for maintaining upkeep of like the common grounds of the university of the buildings and so on. So they did a benchmarking study to see on average what's the response time and the degree to which the request was handled and it's through this recent benchmarking study that it became very apparent that like the library is in total shambles and the bathrooms, students have all kinds of problems. And so an organization might do a study just to see like how is it doing in terms of its internal processes. There's also external studies where an organization like the conference board of Canada or I don't know, the Council of Ontario Quality, council of Ontario Universities will do a study across all of the organizations under its purview. So those are external things and why do benchmarking studies take place? Well, sometimes organizations undertake them because they want to understand how it's performing. Um but also from a kind of bird's eye perspective, there is a desire usually from a government or a pair of public institution to understand the current state of performance in an industry. Why am I telling you all this? It becomes very relevant for design models in just one moment. Okay, so is there a best practice a single best practice for design? No, there is not and I'm going to new onset and it's not just me who saying this, there's like authoritative forces in design methodology that agree that have said this before me And it's already like for more than 10 years we know this, there is no, there is general consensus that there is no set best practice and design process. However, there is agreement that there are some commonalities across processes use and that these typically consists of 4-5 distinct phases And then best in 2006 said although there is no single best practice design process. There are core activities which can be adapted to fit a particular project or situation. So I'm heading towards a picture where we're gonna do prototyping but that prototyping is not prescriptively slotted into like a single best practice. It's a methodology, it's an approach for doing things, but you still need some expertise and knowledge to understand when to prototype in which particular method to use. Okay, more about best practice Clarkson and Eckert. Right, there is a central core of generic stages that constitute a commonality between design processes. These commonalities are modified and adapted to reflect the problem or use or need. They've worded it as problem or user need. We're going to elaborate more on that any moment. There are constraints and drivers that influence the direction of the design process. Give the process, it's project specific characteristics, characteristics. Mhm. So, okay, where does this leave us? So in 2005, it's hard to find the exact date. The British design council, which now has rebranded itself as design council transcending its national borders and perhaps a very british way of doing things. They undertook a benchmarking study of design processes. It was an external study. It got funded. It's not clear how it is funded. It looks to me like it was a company that funded it, it might have been the government I'm not exactly sure, but they function as an outside organization doing a survey across a large set of companies. So it was definitely an external benchmarking study. And why did they conduct this study? It took like a whole year to complete. They gathered information so that they could basically, in the end I want to improve the design sector of the government, of the economy in the United Kingdom. So they wanted to build capacity. So they did it as a kind of business community service. So let's get so much of insights that we can share and all the different UK um design relevant companies. Maybe they're not designed studios per se, but any kind of company that undertakes design can use these insights to like do have better outcomes, which better outcomes means better economic growth and so on and so forth. So that's that's the why of it. What they did is they did site visits to 11 major companies And then they conducted a whole whack of interviews. They did thematic analysis of all the interviews and they did a huge review of like 200 plus scholarly sources on like the design process, design methodology. This scholarly materials would not be in uh computer science, uh publications per se. There is actually in the field of what sometimes gets called fine arts, there's like design scholarship. Design process is coming out of like industrial design, graphic design traditions. So what they found is the double diamond uh design process model. That's the culmination of their big benchmarking study now, Double diamond has taken off on a life of its own. It's now like a bread and butter concept. If you someone could do this, do a google search for double diamond and you'll get like a shit ton of hits because the design community has like loves loves loves this model and said yes, I like a named model and it's very, very established now. But my contention is that it is a design process model. So you have to know what this means and what the implication is for using it. So what is this design process model? How do we use it? Where does produce have been fit in? So it's a model of the design process. So it says like, you know, how does design work? It's a process here. Let's model it it explains and describes prior successes. It doesn't claim to be a predictive model. It doesn't say if you follow this, you will have an optimal design outcome. It's not that's not the thing, it is, it does not give you a recipe, it does not tell you what steps you need to follow. It can be very frustrating for those who are learning about double diamond to say, okay, that's all very nice. The pictures look pretty. I get what it means, but what do I actually do right now? Or given a current state, Like what do we do next? So like that's fine to wonder about what to do. But the double diamond is not going to be the thing to tell you what to do. That. It provides an overall structure. It provides a set of processes and from this structure from these processes, you have to make choices within it. That's, you know, that's all there is to it. It doesn't predictably tell you what to do overall. If you're going to use double diamond, you need a project management approach. So you can use agile, you can use waterfall, lean, incremental, iterative, whatever you need to treat it like a project, it's a design project. It's an undertaking and you have to be able to make choices within that structure. There has to be management, there has to be decision making. You can't um defer the decision making to the model because it won't make any decisions for you. You need process tools. So you need a way to manage all the design documents, you need to handle all these visualizations, all these mirror boards, for instance, that you're gonna be generating lots of diagrams. Um and there needs to be goal setting, timelines and provision for iterations. So we're going to go through the diamonds next and we're going to talk about divergence and convergence and we're gonna talk about like going back and revisiting earlier faces. So these are all things that are not actually in the double diamond process model. That's why we spent time earlier in the course doing like Project Management 101 because you need it in order to undertake this design process. Right, moving on. Here's one particular example. It's not prescriptive, it's not saying here's how you do the double diamond, but it's an example. So you start with something fuzzy, we'll talk about this a minute. You do a research of the literature which can be great or white literature. Great literature is what is white literature is what's peer reviewed and published in archival sources and great literature is everything else. You can interview influential community members, you can do user research, you can do interviews with staff members. You can do a technique called cultural probes tech probes. We'll talk about that more later. So you gather a bunch of information. The white hat round we just did for module three is in here it's a different technique where we're just gathering a lot of information and you might be saying what is all this information for and how does this connect with any kind of user interface. And you would be right to notice that there's a big difference between white hat round and you know this stage of like implementing an interface but it's part of this divergence and then you do analysis and then you produce something at this point, let's call it a problem statement. And then given the problem, you will do a round of ideation, another round of ideation, what are things that respond here? You might use a scamper technique, then you, in this particular process, you do co creation at this late stage, but potentially you can do co creation way earlier, prototyping, Ding, Ding, ding, the theme of this module. And then you know, you start to, they don't show it here, but you're iterating on the prototypes, you start doing testing, but you're using functional prototypes, not functionally implemented code yet. And then you build a plan and then here you have the end and you might ask, what does this thing look like? And this is typically a design Handoff this is not production ready system that the company is ready to sell, but it's some kind of intermediate output that then goes to a development team that implements it. QA team safety analysis team. So this is not like to market, this is feeding into another organizational process. So this is one particular flow, but it doesn't have to be this way, you could ah put all kinds of different approaches in here. The important factor, the thing that makes this double diamond is the divergence, convergence, divergence, convergence and this abstraction between the what and then the house. So what is it that we're trying to respond to and then this is how we're going to respond to the thing and this is why I took a lot of time and energy to talk about asset versus deficit based thinking because if you have a deficit based thinking, your this thing is always going to be the problem statement, you know what is required to solve the problem, but if you have an asset based way of thinking, you can say what's the opportunity here? What's this new thing that we can do that's innovative, that is going to create desire in need in a population of users for which they don't have that already. Okay, so let's continue on the gist of the double diamond. So Donald norman and the design of everyday things talks about double diamond in a really like high level, abstract way. So basically it's like this start with an idea and through the initial design research, expand the thinking to explore the fundamental issues only then it is time to converge upon the real underlying problem. Okay, so deficit thinking here Similarly use design research tools to explore a wide variety of solutions before converging upon one. So this is, you know, Donald norman's take on the double diamond and here's what it looks like the first diamond is you start with an idea something it's called a problem here, through the initial design research, expand the thinking to explore the fundamental issues and then you converge upon the real underlying problem and then here we use design research tools to explore a wide variety of solutions before converging on one. Okay, the double diamonds is formed from four distinct phases, These are discover defined, develop and deliver the shape is generic through it projects but stretched and morphed depending on the projects, characteristics such as the type of product or service, whether they're external suppliers involved or if it is a completely new product or the development of an existing one. Each of the phases consists of iterative loops where exploration and testing of ideas can happen, I lost the attribution of this, but I think it's from british Design Council. So you know, each of these phases has loops and then within those loops we have these four core activities but they're going to look differently depending on where you are in the process. And all of this is assuming a human centered design process as opposed to technology center design process. I'll talk about that in a second. Okay, so here we have I guess a schematic in the Discovery phase because things are so fuzzy at the front end there, you know, it's not clear how you're iterating, although I would argue that thought experiments and like running through scenarios and mental maps is the kind of prototyping and evaluation. There is a feedback loop there, but really it's in the second diamond that you see this more distinct Uh iteration over the four core activities. So I just want to talk for three slides about uh divergence and convergence because each of the two diamonds has diverge coverage. So what's the point of divergence? The purpose of diversions is you want to generate a lot of variants and options. This is familiar because I said this again and again in the last module, you know, you have diverged successfully if you have a large number and a good quality of different variants and options, that's, that's the whole point of it, you don't judge a divergence phase by do I have a single good solution? That's not the point of it. So you want to have this large slate of options? Why? Because the later phases needs them. So it's delayed gratification. You don't know what the thing is that you want to land on yet, but at least you have generated a good set of options. And the, the, the good solution, let's say is either among the auctions or it's going to emerge out of putting together some of those options and perhaps an unexpected way you can diverge on so many things. So you can generate a large set of ideas about design problems, opportunities, design concepts, you can have a lot of variants for a given kind of design concept, You can have a lot of user scenarios when a particular um, let's say assemblages coming together. So white hat is, you know, user scenarios, all those personal facts are going to generate a huge set of user scenarios. There's like 300 of them there. Then you can use research techniques to let's say analyze all of those use scenarios of individuated tests in that case and themes can emerge. And from those themes you can Have the spark of an opportunity or identify a problem that can be responded to in the 2nd diamond. Mhm. For a given scenario, you can storyboard it in a lot of different ways. You can build a lot of different prototypes, you can have a lot of different design elements so on and so forth. Convergence is, you know, the complement of divergence. You're trying to refine it, narrowed down the input to a convergence stages, a large set of things. And, you know, you've done a good job in the convergence phase. If you've been able to successfully narrowed down and made a good choice where quality or good, really depends on the context. So, if you have a large set of prototypes, you need to select one of them for further development or if you have a large set of personas, we'll talk a minute later in the research phase about what that means. You want to choose one to be the primary persona. If you have a large set of design problems and opportunities, you want to select one to be the focus of a design response. Okay, now, I'm going to talk about the two diamonds and situate prototyping in the second diamond. Mhm, let's check the time. Okay, So there's two diamonds to talk through. I'm just using diamond one diamond to his convenience. That term is not actually used so much both of the diamonds as I said, make use of iterative approaches but the core activities kind of kind of, they do look different depending on which diamond you're in. But it's in the second diamond that the thing that we recognize as iteration is most legible and apparent. So now I'm going to talk about the first diamond, which is the discover defined diamond. So it's a consists of divergence convergence at some point the discover fage, which is divergence has to pivot into define which you start to narrow down the whole point of this. First diamond is to produce what I will call an artifact by artifact. I just mean like a thing, it's usually written in some form in words or diagrams or somehow and it communicates basically this is the thing that the second diamond is going to respond to and I struggle with terminology because the thing you call it, it's so specific to the design context and it's so specific to like the way of thinking often this thing is called the project brief. Sometimes you see that more in, you know, design studios and so on or you see like a web design brief, for instance example, that's what that might look like or a statement of the problem, statement of requirements, design concept. Sometimes there's like a design concept stands in for the statement the project brief. Yeah, it gets called a lot of different things. Let's just call it the what? But what is the thing. And then the second diamond is like, how are you going to address it? I'm going to talk about discovering, define here in this first diamond. This thing often gets called the fuzzy front end F. I love me a good acronym. It's the phase during which ideas form and in companies or different organizations this face sometimes it's happening and it doesn't get called this, it's not formalized, but ideas percolate in all kinds of interesting places and then they come together. So it's it's the place where like all the brainstorming about like what is the situation and what do we need to be doing about? It emerges. This studies show that quality of this discovery phase, like how diversion, how wide, how loose, how fuzzy, even though it looks unruly and it looks like you're not being optimal or effectual. It's actually critical to the actual thing that gets defined. So if you skimp on discover, then you pay later. And it's just one of those things if you're not experienced and you think this is a waste of time, you just have to be open to being convinced that it's actually not the case at all. And it's so counterintuitive that this divergent messy stage is so crucial because it's just so much at odds with are thinking about being productive and honing in on the problem and being ineffectual. It requires you to be at peace and comfortable with messiness and unruliness and it's unstructured. But there's all kinds of methods that can be used to discover things that are relevant. So market research, you can buy market research reports, you can do qualitative user research methods, focus groups, interviews, probes, you can use ethnographic approaches. We haven't talked about that. We can use team approach is brainstorming, we can use visioning, rapid sketching. There's like shit tons of these techniques like hundreds of them really. This pays often covers a significant amount of design activity that goes on with an organization but it doesn't get acknowledged as being part of the design process. That's just you know, only in retrospect you're like oh that was the fuzzy front end of our design process. But in the moment you don't realize it's the design process. Yeah the divine phases filtering. So you're converging after the messiness of the discover your ability to do well in this phase really depends on the big set of materials that you're working from. You can use all kinds of tools and methods to converge. There's all kinds of thematic analysis. You can use visual or written. You can do motivation analysis, obstacle analysis. Journey mapping is often used at this point. Um this results in the thing that I struggled to call, it's called problem definition design brief. It's some kind of artifact and like what makes a design brief for what makes this artifact. It has to be actionable. It has to be goldilocks specific enough that you can do something but not so specific that it has predetermined the solution already. This missing notification. Okay, so at the end of the diamond one, you have some kind of artifact, project brief, a problem, statement, statement of requirements, design concept. So honest before basically the artifacts spells out what the second diamond is going to do. And then at the end of the first diamond you're going to have a whole whack of design material. You know, you're gonna have all these materials research materials, ideation materials, etcetera. If you're running a design process as a team, you have to come up with a system to wrangle all that stuff. So already in your pods you have either formally set up like a google drive or some kind of cloud based storage. Put everything there for your pod or informally, you know, in your brains, you know, who has what So you've already seen through your pods. The issue of keeping track of all the stuff that's a perpetual issue transition point is here. So what happens between the 1st and 2nd diamond, what that actually looks like? Depends on the design context. In some design context, it's not going to be formal. Just the team will slide into the next diamond, but in other contexts like companies, corporate, certain organizations there's a formal sign off. You don't get to move to the second diamond until there's some kind of approval or sign off because there are resource implications. The design team has, however, it was assembled, spent time and energy on the first diamond and that's like cost, right costs to do that, you have to be released from your other duties, your manager has to agree for you to spend x percent of your time on this and the project doesn't. Those resources don't get allocated for the 2nd diamond until certain conditions are met. So usually the sign off is contingent on the design brief for the concept or the problem statement has to be aligned with the organization's objectives or emissions because the thing that comes out the other end has to be relevant to what it is, the organization is doing, The measurement of outcome has to be agreed upon. How do we know if we have succeeded and the bottlenecks and opportunities have to be identified as well as no go areas like you can do what you want, but you cannot for instance go and um have any impact or compete with this other product line or you may not differ from um you can't, you have to stay in this particular digital platform, you can't shift to a different platform, so kind of the constraints get established at that point. Okay, now we're going to get to eventually the prototyping, so the design, the developed deliver, so the developed phases divergent. Often you have a big multidisciplinary team because you want to have ideation with design tension, you know what you think? You don't want everyone thinking the same, their successive iterations of those four core activities, there's usually a lot of visual techniques for the team to see iterations of sketches, prototypes and other design work because you want to be working on a thing. Mhm. There's multiple variants, repeated iterations of core activities. So under the research phase and generating ideas, there's going to be a lot of scenario persona development, storyboards, plus minus scenarios, prototyping, there's going to be a lot of techniques, low fidelity techniques. We're going to use different prototyping software packages and in evaluation testing you're going to depending on the maturity of your prototype, the prototype you need in order to do the testing, you're either going to be able to do, walk throughs observational studies later on, you can do with their DeVos studies, you can actually do usability testing with functional prototypes and so on and so forth. Okay at this point, you have a whole set of things, a lot of different prototypes, a lot of different ideas. You start to converged down and like I said at the end, the solution is not the thing that gets deployed out into production into the market or into the organization. It's the handoff that goes to the next team. Uh So at that point you're making decisions about what the targets are target outcomes and what kind of measures you're going to use to check to see if you achieve the targets and you're going to start to provision for feedback from whatever happens afterwards, to feed back into the design process to track for things. Okay. So in some there is no single best practice for design. Ah There is just practice that's effective, that's thought to consist of certain core activities but it's really going to depend on the project. And the now popular double diamond model is not the best practice but more of an overarching model of many successful practices. Okay, so let's get to the design the prototyping. Okay so I just want to clarify prototyping is used in many different realms. So if you're doing I don't know like civil engineering, you do prototyping there. But civil engineering is not a human centered design process. So I just want to talk about what H. C. D. S. Or sometimes it's called you see the user centered design. So first let's start with the foil. What is technology center design And it's one of these things that doesn't get called this too often but it's kind of like the norm, the baseline. It's the thing against which everything else gets compared. So this in technology center designed the technology is essential focus. So all the software development methodologies. Software engineering is a technology center design approach. So software design puts software is the central focus the premise of technology center design is so totally different than human centered design. The premise is that requirement gathering is the key activity. It gets called different things, requirements solicitation requirements gathering automatic department analysis so on, it's all about requirements, the design process, Technology center design process, response to the requirements and the users role in this Technology center design processes via their participation in the requirement development. There is a role for the user, the end user, but it's in that stage. So the crawler is that the statement of requirements is mediating the user's involvement in the process. Here's just a scenario that I'm going to make exaggerated because I'm going to illustrate a point. So the user says to the design team, you built this system for me, let's say this payroll reporting system or this like hours tracking system or this word processor or whatever. You built this system for me, but I don't like how it behaves. And then the developer, the designer says, but you said you wanted X when we collected the requirements and the system does this. So like I've covered off my end. So the requirements and establishing the requirements is like the key pivot point in the technology center design process because once you have the requirements, you don't include the use or anymore, you're doing everything for the requirements. So in human centered design, it's not on the technology, it's not on the requirements. You focus on the user throughout even after you have like the problem statement. But you know, it's incomplete. You acknowledge with humility that your requirements can ever actually capture everything. So you're always going to inviting involving the users and the tasks and their environments all throughout. Even after you have this, you know, middle artifact between the two double the two diamonds. So there's three core principles in human centered design. So you need to employ an iterative approach. The focus on the user has to come in early, not late. And by that it's like not at the final testing stage. And all the decisions should be made on the basis of empirical evidence. Not the designers own idea of what the user wants or how the user behaves, but actually on how the user does those things. You can't make empirical decisions if you don't have prototypes. So I think we've already talked about the iterative approach quite extensively. I'm going to skip over this. Yeah. The early focus on the users. So we're going to talk about this but we make use of a persona technique. We're going to use different frameworks when we think about users, not just cognitive but looking at their attitudes, their emotions, their social lives. There should be a focus on users engaged in activities in their environment. So situated not artificial, there's many different approaches to capturing data about how users do undertake their activities in their environments. Scientific observation, anthropology, logical. So ethnographic approaches. And there should be a focus on involving users in the design process. Okay, so we're going to talk about empirical decision making and prototyping now. Yeah, so prototyping is the experimental process where design teams implement ideas into tangible forms and those tangible forms range from paper to digital instances. Teams build prototypes of varying degrees of fidelity to capture design concepts and tests on users with prototypes. You can refine and validate your designs. So have you heard of this proverb? You go slow to go fast. This is the case with prototypes, prototypes slow us down to speed us up by taking the time to prototype our ideas. We avoid costly mistakes such as becoming too complex, too early and sticking with a weak idea for too long. So I can illustrate this. I'm on a design team right now That's funded $300,000 project and the way the project run is not using double diamond and I'm not the single uh I'm not in charge of the project, I'm just a team member and I've provided input into the methodology but for whatever reason this is not being followed. And the team is literally prototyping directly in unity right now and I don't want to talk about too many details because I don't want to expose the team but You think that this is obvious. Of course you test things out in a low stakes, cheap and easy way before you invest heavily into implementation. But I can tell you like right now at this moment in 2021, there's a big major project that is skipping the prototyping directly and just every idea is getting implemented in the production environment directly and ask me how I think this is going to work out. Mm Yeah, I don't think it's going to work out well because it's so time consuming and expensive to implement, that's really going to constrain the number of different ideas that can be explored and the overall outcome is not going to be as good as it could have been if we have Instead taken one or 2 months to do prototyping in paper and pencil and sigma first. But this is a team with lot of engineers that are trained in engineering Design and Engineering design is a technology center design methodology as opposed to double diamond, which is a human centered design approach. So we see disciplinary tensions and how things get done. Okay, here's an awesome video. I want to show it. Do I have time? I think I have time. It's quick. Plus Alan Dix is like an awesome figure Get out. I'm just going to pop up the video right now. I had to re share because I need to share the here it is. It reminds me of like, I don't know uh Lord of the Rings or something. Okay, I'm gonna play this go. Alan mhm.

SPEAKER 1
So why do you need prototyping?

SPEAKER 0
Can you hear it? It's okay, Cool, let me see the chat. Where did it go? Crap. Okay, a bit good. Okay, Alan Dix is one of the like foremost kind of design experts. So he's written several important textbooks and lots of publications. So um yeah, if you're wondering like, why are we listening to this and dude, it's supposed to someone else. That's the reason.

SPEAKER 1
Well, we never get things right first time, it's about getting things better when they're not perfect. And also starting in a good place. Maybe if I'm going to make a wall for a house, I know exactly how big the wall should be. I can work out how many bricks I need. I can make it exactly the right size so I can get it right first time, it's important to I don't want to knock the wall down and retry it several times. However, there I have very clear idea of what I'm actually creating with people involved. When you're designing something for people. People are not quite as predictable as brick walls. So we don't get things right first time. So the sort of classic cycle, you know, you design something, you prototype it. Um and that prototyping might be, you might sort of get a pad of paper out and start to, you know, sketched a design of what your interface is going to be like and talk through it with somebody that might be a prototype. Um It might be making something out of the blue foam or out of cardboard or it might be actually creating something on a device that isn't the final system, but it's a make do version something that will help people understand. You make some sort of prototype, you give it to real users, you talk to the real users who are likely to be using that about it. You evaluate that protest, you find out what's wrong, You redesign it, you fix the bugs, you fix the problems. You mend the prototype. You make a different prototype, has to make a better part of a higher fidelity prototype. One that's closer to the real thing. You trust it again, evaluated with people round and round and round. Eventually you decide it's good enough, good enough probably doesn't mean perfect because we're not going to get things perfect ever, but good enough and then you decide you're going to ship it. That's the story. Yeah. In certain cases, in web interfaces, you might actually release what in the past might have been thought of as a prototype because, you know, you can fix it and they might not be an end point to this. So you might in delivering something and this is true of any product actually, when you've finished it, you haven't really finished because you'll see other problems with it. You might update it, create new versions, create updates. So in some sense, this process never stops in one way, it's easy to get so caught up with this iteration. That is an essential thing that you can forget about actually designing it well in the first place, now that seems like, you know, a silly thing to say, but it is easy to do that, you know, you're going to reiterate anyhow, you try something and there are sometimes good reasons for doing this, you might have so little understanding of Office of the domain that you try something out to start. However, then what you're doing is creating a technology probe, you're doing something in order to find out of course what's easy then to think about is to treat that as if it was your first prototype to try and make it better and better and better. Trouble is if it didn't start good, it might not end up very good at the end despite the duration. And the reason for that is a phenomenon called Local Maximum. So what I've got here is a picture, you can imagine this is the sort of terrain somewhere and one way to get somewhere high. If you're dumped in the middle of a mountain place, if you just keep walking uphill, you'll end up somewhere high and actually you can do the opposite as well if you're stuck in the mountains, you want to get down the obvious thing is to walk downhill and sometimes that works and sometimes you get stuck in a gully somewhere. So imagine we're starting at this position over on the left, you start to walk uphill and you walk uphill and you walk uphill and eventually you get onto the top of that little nodule, there wasn't very high. Now of course, if you started on the right of this picture near the big mountain and you go uphill and you go uphill and you go uphill and you get that pill, you eventually end up the top of the big mountain. Now that's true of mountains, that's fairly obvious. It's also true of user interfaces. If you start off with a really dreadful design and you fix the obvious errors, then you end up with something that's probably still pretty dreadful. If you start off with something that's in the right area to start with, you do better. So on my eyes stop and say just notice the

SPEAKER 0
disciplinary effects here. Oh my alarm is going off that if you're coming from a discipline where you have taken um any kind of like analysis, calculus and so on, you know, the difference between a local and a global minima or maxima and if you've done machine learning, you know about, you know, uh kneeling and these approaches. So you understand this idea of like local maximum and global maximum in a different way than the video, which is not assuming that the audience has this mathematical background, I just noticed it's interesting if you know, you're talking to a class of students in like digital media and computer science, you could just do like two seconds on this. This is a local maximum but they had to explain it with a nice picture in the mountains and yeah, it's you students in this class might not necessarily be the target audience for this because they're not assuming any mathematical background continuing on.

SPEAKER 1
So I've actually the example of it on the side of the mall vins, the Melvins are a set of hills in the middle of the UK, somewhere to the south west of Birmingham and the highest point in these hills is about 900 ft. Um but there's there's nothing higher than that for miles and miles and miles and miles, so is the highest point, but it's not the highest point. Certainly in Britain, let alone the world. If you want to go really high, you want to go into Switzerland and climb the Matterhorn or two to Tibet and go up mount Everest up in the Himalayas, you'll start somewhere better. Right? So if you start or on the island, I live in Ontario, the highest 0.120 m. So if you start on terry and keep on walking upwards you don't get very high, you need to start in the right sort of area and similar with user interface, you needed to start with the right kind of system. So there's two things you need for an iterative process, you need a very good starting point, it doesn't have to be the best interface to start with but it has to be in the right area, it has to be something that when you improve it will get really good and also and this is sort of obvious, but actually it's easy to get wrong, you need to understand what's wrong. So when you evaluate something, you really need to understand the problem, otherwise what you do is you just try something to fix the obvious problem and ending up maybe not even fixing the problem but certainly potentially breaking other things as well, making it worse. So just like in the, if you're sort of trying to climb mountains, you need to start off in a good area, start off in the Himalayas, not on Tyree, um you also need to know which direction is up. If you just walk in random directions, you won't end up a very high place. If you keep walking uphill you will. So you need to understand where to start and understand which way is up for prototyping, your user interface, you need a really rich understanding of your users, of the nature of design, of the nature of technology you're using in order to start in a good place. Then when you evaluate things with people, you need to try and really deeply understand what's going on with them in order to actually make things better. And possibly even to get to a point where you stand back and think actually all these little changes are making are not gonna, I'm not making a really sufficient different stall. I'm going around in circles sometimes you have to stand right back and make a radical change of design. That's a bit like I mean climbing up the mountain and suddenly realized that I've got stuck up a little peek and I look out over there and there's a bigger place and I might have to go downhill and start again somewhere else. Mhm Yeah. So iteration absolutely crucial. You won't get things right first time you always need to. Its right. So prototyping all sorts of prototypes from paper prototypes to really running code very, very important. However crucial to design is having a deep and thorough understanding of your users, a deep and thorough understanding of technology and how you put them together.

SPEAKER 0
Okay, that's the end of the video. Let me get back to here. And I just want to comment briefly. I, as I was watching the video, I was thinking of the white hat and green hat round that. We're just in the middle of right now and I just want to hold the two things up. So if I gave to you as an assignment, look at Procter track and design an improved version. What does the interface of Procter tracks look like and come up with a different version probably in this class, there would be all kinds of tweaks and improvements to that. But we ask ourselves like are you starting in the right place? So, you know, is that demonstrating a thorough understanding of what the issue is? What is the issue? We did. That big collection activity where the image elation and the stress of the online test was flagged as one of the key themes when we did this open activity with the class and as a prompt for the ideation activity. That image elated online tests are problematic but for different reasons is a way to explore the whole space so that we can find ourselves a good starting place. If I ask you design a solution to this problem brief, then it's not it's not undertaking an analysis what truly the problem is. So that's why I use that prompt because it's connected to the concerns of the course, the students in the course and it's a really rich kind of domain for what is really the core issue here. What's the true nature of the problem? Do we want to just like iterate on, you know, the particular technology that's used for uh in vigil ation for surveillance during a test or is the the true nature of the problem sitting somewhere else? Mainly that because of the pandemic, we're now in a paradigm shift to a lot of online learning right? Like what we're doing right now in this moment. So I'm using that as a kind of case in point for how to tackle. Use what will become a user interface design task, but in a really like holistically embedded way. Okay, continuing on because we've got to finish this in the next five minutes and let me just acknowledge that it turns out that some subset of the quizzes um didn't get marked because of one of the questions that got randomly chosen. So not everyone has their quiz results right now, and this is going to just take a little bit of attention after class. So we're going to do the quiz to review when everyone has their quizzes back, so we're not going to do it today. Sorry about that. Yet another delay, but we will do it, I promise. Okay, so I just want to finish now the last few slides on prototyping because I want to get us to the point where you're standing by the module for activity is going to launch by the end of this week and then it will be due um the week of, let me just check the date. You'll have more than a week to do it. Yeah, it will be due on the 20th, so it's two weeks from now. So let's just get to that point and then you're gonna wait for the activity to launch. So this slide is just also providing rationale for how early prototyping seems to take a lot of time up front, but it actually prevents costly errors in advance, so announce the prevention is worth a pound of cure is the proverb I really like. We have a lot of motivations for prototyping. You want to establish a good foundation. You want to have concrete form for ideas. You want to have a way to communicate. You want to provide a sense of ownership to all concerned stakeholders. This fosters uh, emotional investment in the product's success. You want to provide a basis for discussion with stakeholders. So often you have the concrete prototype is a good way to do this. You provide a picture of the potential benefits, risks and costs associated where prototype might lead. You want a provision for adaptability. You can make changes easily early on as opposed to investing heavily into a big implementation. You can improve time to deployment by minimizing the number of errors to correct more motivations. You want to have something to show users so they can give you their feedback and help you pinpoint which elements variants work best whether an overhaul is required and you want to have something. This is the empirical ah basis. The three things that are irrelevant for human centered design. You want to have something to provide the basis for experimentation because the prototypes are functional that can be used. The users can interact with them. Maybe not like it's fully functional interactive product, but even a paper and pencil sketch, you can hold up, you can have someone do a walk through, they can point to it, you can say if you had this, what would you do first. So you can use even a very simple paper and pencil prototype and um, scenarios even have people do scenarios. Okay, wireframe, the term wireframe gets used a lot. And I just want to clarify what it is. A wireframe basically. It's a schematic or blueprint of something at one time, wireframe was used to imply a particular kind of product in web design, but now it's used more generally for any kind of schematic representation for web design. The wireframe was the outlines of the windows. Everything was like window based and widget based. So instead of populating the prototype with the actual like buttons and the actual banners and the actual picture picture elements, you would just put boxes to represent those things. So it was looks like wires and they were called wire frames. But now wireframe just means something way more general. Okay, now I'm going to talk about low medium and high fidelity prototypes. So a low fidelity prototype looks like this kind of thing, paper and pencil to sketch it can be on a napkin. Uh, it's quick and simple. It outlines the interactive systems flow but through like uh, elements of graphic design. So from right to left, you know, because that's the dominant reading direction in the english language, but in other cultures that are right to left. The prototypes will flow the other way right here, You see it. So these things are culturally embedded. It's not visually refined, at least as compared to high fidelity prototypes. So here you have here it's clickable. But you know, you don't have the actual elements. You just have like some kind of placeholder. So pen and pencil drawings for sure are low fidelity paper prototypes using officer craft supplies. Or click through prototypes. Whoops. This is module for activity. It's not responsive in a native way. It's emulated. But it's, you know, faking the interaction. The remember in the video we saw like a long strip of paper with like a cardboard template that you can slide along. That's an example of a low fidelity prototype. It's meant to show screen flow, but you do it by faking it with craft supplies. Okay, It's 11 20 I have former slides. So let me just finish. High fidelity prototypes are more advanced than low fidelity. There elaborated with their aesthetics and the elements. Their function is closer to the final product, but it's not a final product. So, you can have interactive prototypes. You know, the elements are kind of medium fidelity but the flows are more elaborated. Digital prototypes are, you know, uh full of rich aesthetic elements. Lots of typography has been and added font faces, color palettes, animations. Other effects are included. You can have prototypes that you can actually code in. Html. CSS CSS And that are natively response responsive. So when we're doing our activity, we're gonna be doing sigma were used stigma in this sense low fidelity and then later we can elaborate on this initial low fidelity sigma prototype and make it higher fidelity. What are you prototyping? That that is you know you need to design concept to respond to but I need the green hat round to finish so that we can mind the design concepts from that data and give it to teams and you can choose one of the small curated set of design concepts that we're going to device from there. Okay, so the last principle is the empirical decisions. So you are going to express design concepts via prototypes and then the prototype establishes the foundation and then the prototypes are representing decisions to be made and then you have users interact with the prototypes and you gather data from that interaction and you use this as the basis for the iteration. Going forward. This slide talks about this in a lot more detail but I'm limping over it really fast because I just want to get to my ending point. I'm gonna skip this but please read it on the quiz for module four. There's always a question on genius design. So I'm gonna just identify it here. Um and then we're going to connect to the module for activity. Um Ricky is just side channeling with me. That mural also has a wireframe library. It's true. Absolutely. And it's also a very good tool for low fidelity prototyping. I feel like at this point we have a good grip on mural and I want you to learn sigma. We can hold them side by side and sigma has a good potential for flows. So we're not going to use a lot of flows at this point, but just a basic one. But later you can build a flow and you can actually launch an interactive prototype. But thanks for pointing that out. There's a lot of other tools other than sigma for sure. Um, and you know, all different things, but we're not going to get into it. So the module activity, the goal is just to establish the core concepts and prototyping, which is frame components and the flows and the actions. Okay, so I'm going to stop now. I talked for a long time with not much feedback, but I'm going to pause now. There's a little bit of time for questions. I'm going to stop the recording
